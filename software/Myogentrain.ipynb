{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da0d8fb-2086-434a-8f90-4e024b61881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4216b00802d44f2c820e9875b9d950f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319295d77d5843ab9aa23ebc2542d36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383b865ec3e54c6395757d87c4ff9ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d02e13fc58a44338f027a731d53b7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('/workspace/oss20b-orpo/checkpoint-final/tokenizer_config.json',\n",
       " '/workspace/oss20b-orpo/checkpoint-final/special_tokens_map.json',\n",
       " '/workspace/oss20b-orpo/checkpoint-final/chat_template.jinja',\n",
       " '/workspace/oss20b-orpo/checkpoint-final/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip -q install \"trl>=0.20.0\" \"peft>=0.17.0\" \"transformers>=4.55.0\" datasets\n",
    "\n",
    "import torch, random, os\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Mxfp4Config\n",
    "from peft import LoraConfig\n",
    "from trl import ORPOTrainer, ORPOConfig\n",
    "\n",
    "jsonl_path = \"/workspace/orpo_pairs_best_contact.jsonl\"   # {\"prompt\",\"chosen\",\"rejected\"}\n",
    "output_dir = \"/workspace/oss20b-orpo\"\n",
    "model_name = \"openai/gpt-oss-20b\"\n",
    "seed = 7\n",
    "\n",
    "random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "quantization_config = Mxfp4Config(dequantize=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    attn_implementation=\"eager\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quantization_config,  # MXFP4 → dequantize to bf16 for LoRA\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8, lora_alpha=16, lora_dropout=0.05,\n",
    "    target_modules=\"all-linear\",  # works with oss-20b; expand if you later target MoE experts\n",
    "    bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "ds = load_dataset(\"json\", data_files=jsonl_path, split=\"train\")\n",
    "\n",
    "args = ORPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    logging_steps=20,\n",
    "    save_steps=500,\n",
    "    beta=0.1,\n",
    "    gradient_checkpointing=True,\n",
    "    bf16=True, tf32=True,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "trainer = ORPOTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    train_dataset=ds,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(os.path.join(output_dir, \"checkpoint-final\"))\n",
    "tokenizer.save_pretrained(os.path.join(output_dir, \"checkpoint-final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47221e0d-50ed-4e4c-831b-755bdbdf3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb01ca184b04bfea828061b513a26be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42856965f0c949f2b10ad85f814dec4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d702558d1a7494985d2d2c91e4a340e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546fd23ae3ca4dbead1292b7cf72feb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...rpo/checkpoint-final/tokenizer.json:  30%|###       | 8.38MB / 27.9MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477ff70438564e7a8d36075a2cde2118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...int-final/adapter_model.safetensors:   0%|          | 21.4kB / 16.0MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d242e285fc2643b2925c8fc3d36e1949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  .../checkpoint-final/training_args.bin:  73%|#######2  | 4.45kB / 6.10kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed to: https://huggingface.co/punnettsquare9331/myogen-orpo-lora\n"
     ]
    }
   ],
   "source": [
    "# Install + login\n",
    "!pip -q install -U huggingface_hub\n",
    "from huggingface_hub import login, HfApi\n",
    "login()  # paste your HF token\n",
    "\n",
    "# Paths\n",
    "ckpt_dir = os.path.join(output_dir, \"checkpoint-final\")  # from your script\n",
    "repo_id = \"punnettsquare9331/myogen-orpo-lora\"                   \n",
    "\n",
    "# Save tokenizer into the same folder (so the repo is self-contained)\n",
    "tokenizer.save_pretrained(ckpt_dir)\n",
    "\n",
    "# Optional: add a minimal README\n",
    "readme = os.path.join(ckpt_dir, \"README.md\")\n",
    "if not os.path.exists(readme):\n",
    "    with open(readme, \"w\") as f:\n",
    "        f.write(\"# oss20b-orpo-lora\\n\\nLoRA adapter trained with ORPO on HO3D pairs.\\n\")\n",
    "\n",
    "# Create repo and upload the folder\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id, private=True, exist_ok=True)\n",
    "api.upload_folder(\n",
    "    folder_path=ckpt_dir,\n",
    "    repo_id=repo_id,\n",
    "    commit_message=\"Upload ORPO LoRA adapter + tokenizer\",\n",
    ")\n",
    "print(\"Pushed to:\", f\"https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d329f7c-638f-447f-a8dc-1128c10e0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# Empty the CUDA cache\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0edf18-f5d4-41d6-b344-7e728e30a958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e56d5e67f4428f959c194d6fc3e6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97d4cdb270b4750865d857530931c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/27.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44444a5cfbe452b850c38f1a5779641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/98.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db4f67b9f6a4bdb895372a121ee0311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725033c378da43e08a84369219375fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f473b711fb084fcc86b2a13ff78640ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b4e487adac41eab411c00d2c549ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9009896f23454439bef78428e9bdbf5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e17327f8764c6686bdb437dcc483f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacc33c99da24d91ac9a321238feb4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00000-of-00002.safetensors:   0%|          | 0.00/4.79G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7a2dc3772649c187358635737813d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68931f8027d4b3fa8f4729b060a8c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged model to: /workspace/oss20b-orpo/merged\n"
     ]
    }
   ],
   "source": [
    "# Paths (adjust if needed)\n",
    "!pip -q install \"trl>=0.20.0\" \"peft>=0.17.0\" \"transformers>=4.55.0\" datasets\n",
    "base_id = \"openai/gpt-oss-20b\"\n",
    "adapter_dir = \"/workspace/oss20b-orpo/checkpoint-final\"   # your saved LoRA\n",
    "merged_dir = \"/workspace/oss20b-orpo/merged\"\n",
    "\n",
    "import os, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Mxfp4Config\n",
    "from peft import PeftModel\n",
    "\n",
    "os.makedirs(merged_dir, exist_ok=True)\n",
    "\n",
    "# Load tokenizer\n",
    "tok = AutoTokenizer.from_pretrained(base_id, use_fast=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Load base with MXFP4 dequantized to bf16 for merging\n",
    "quantization_config = Mxfp4Config(dequantize=True)\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    base_id,\n",
    "    attn_implementation=\"eager\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quantization_config,\n",
    "    use_cache=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Load adapter and merge\n",
    "peft = PeftModel.from_pretrained(base, adapter_dir)\n",
    "merged = peft.merge_and_unload()   # returns a regular transformers model\n",
    "\n",
    "# Save merged model + tokenizer\n",
    "merged.save_pretrained(merged_dir, safe_serialization=True)\n",
    "tok.save_pretrained(merged_dir)\n",
    "print(\"Saved merged model to:\", merged_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c4fa52-ca81-427a-bc9c-88fe793fdf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd811b42f7344d04b57a7f61e7bc1840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5ba56ae0574b079097b726a42fd389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa66e3ac5f2d4ca1be1a1ecbc52fb0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57011405bcc454aa565eb5e8237aa47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00008-of-00009.safetensors:   1%|          | 41.9MB / 4.94GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab142710e0ce423a9fbb52a0516db734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00007-of-00009.safetensors:   1%|          | 33.5MB / 4.94GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c2159537c34ed09e093194b0eb1e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00002-of-00009.safetensors:   1%|          | 25.1MB / 4.94GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceeb0fd9fec44fcf9fd7ec70a9dbc384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00003-of-00009.safetensors:   1%|          | 25.1MB / 4.94GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c410fe152342a5ba4042c8f80567e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00001-of-00009.safetensors:   0%|          | 8.38MB / 4.50GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a952df104524b80bf2520da77fc4ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00006-of-00009.safetensors:   1%|1         | 58.7MB / 4.94GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15ec392867e4157981e8770de6fd346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00004-of-00009.safetensors:   1%|          | 41.9MB / 4.94GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32bb8fc471b4769b51db0220ca80a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00005-of-00009.safetensors:   1%|1         | 50.3MB / 4.94GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095f63530274403683775ef611721c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...e/oss20b-orpo/merged/tokenizer.json: 100%|##########| 27.9MB / 27.9MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba7457d539548be9c7fd7866251251e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00009-of-00009.safetensors:   0%|          | 8.38MB / 2.75GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed: https://huggingface.co/punnettsquare9331/oss20b-orpo-merged\n"
     ]
    }
   ],
   "source": [
    "!pip -q install -U huggingface_hub\n",
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "login()  # paste token\n",
    "\n",
    "repo_id = \"punnettsquare9331/oss20b-orpo-merged\"  # change this\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id, private=True, exist_ok=True)\n",
    "api.upload_folder(\n",
    "    folder_path=merged_dir,\n",
    "    repo_id=repo_id,\n",
    "    commit_message=\"Upload merged ORPO model (gpt-oss-20b + LoRA)\",\n",
    ")\n",
    "print(\"Pushed:\", f\"https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d477f0-cb51-4908-9cca-b3ec2c2d90ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
